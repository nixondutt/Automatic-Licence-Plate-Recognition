[net]
# Testing
batch=1
subdivisions=1
# Training
#batch=64
#subdivisions=1
width=96
height=64
channels=3
momentum=0.9
decay=0.0005
angle=0
saturation = 1.5
exposure = 1.5
hue=.1

learning_rate=0.001
burn_in=1000
max_batches = 50000
policy=steps
steps=10000,30000, 48000
scales=.1, .1, .1

[convolutional]
batch_normalize=1
filters=16
size=3
stride=1
pad=1
activation=leaky

#[maxpool]
#size=2
#stride=2

[convolutional]
batch_normalize=1
filters=32
size=3
stride=1
pad=1
activation=leaky

[maxpool]
size=2
stride=2

[convolutional]
batch_normalize=1
filters=64
size=3
stride=1
pad=1
activation=leaky

#[maxpool]
#size=2
#stride=2

[convolutional]
batch_normalize=1
filters=128
size=3
stride=1
pad=1
activation=leaky

[maxpool]
size=2
stride=2

[convolutional]
batch_normalize=1
filters=256
size=3
stride=1
pad=1
activation=leaky

[maxpool]
size=2
stride=2

[convolutional]
batch_normalize=1
filters=512
size=3
stride=1
pad=1
activation=leaky

[maxpool]
size=2
stride=1

[convolutional]
batch_normalize=1
filters=1024
size=3
stride=1
pad=1
activation=leaky

###########

[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=1
filters=512
size=3
stride=1
pad=1
activation=leaky

[convolutional]
size=1
stride=1
pad=1
filters=45
activation=linear



[yolo]
mask = 3,4,5
anchors = 19.91,35.94, 22.42,38.51, 19.55,31.05, 26.67,40.9, 34.8,22.4, 31.12,43.94
classes=10
num=6
jitter=.3
ignore_thresh = .7
truth_thresh = 1
random=0

[route]
layers = -4

[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=1
activation=leaky

[upsample]
stride=2

[route]
layers = -1, 6

[convolutional]
batch_normalize=1
filters=256
size=3
stride=1
pad=1
activation=leaky

[convolutional]
size=1
stride=1
pad=1
filters=45
activation=linear

[yolo]
mask = 0,1,2
anchors = 19.91,35.94, 22.42,38.51, 19.55,31.05, 26.67,40.9, 34.8,22.4, 31.12,43.94
classes=10
num=6
jitter=.3
ignore_thresh = .7
truth_thresh = 1
random=0
